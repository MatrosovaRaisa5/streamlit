# -*- coding: utf-8 -*-
"""код.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11jIIujNUygCzqylABo5NJftKIxkz3YPb
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab import drive
import seaborn as sns

drive.mount('/content/drive')

df = pd.read_csv('drive/MyDrive/weatherAUS.csv', encoding='utf=8', sep=',', parse_dates=['Date'])

df

# df=df.sample(50000, random_state=42)

df.info()

df.isnull().sum(), df.isna().sum()

cols = ['Date','Evaporation', 'Sunshine', 'Cloud3pm', 'Cloud9am', 'Location']
for col in cols:
  df.drop(col, axis=1, inplace=True)

df_remove=df.drop_duplicates()
df_remove.shape

for col in df_remove.columns:
  if df_remove[col].dtype == 'float64':
    if (df_remove[col] % 1 == 0).all():
      df_remove[col] = df_remove[col].astype(int)
      print('int')

df_remove.info()

X=df_remove[[col for col in df_remove.columns if col!='RainTomorrow']]
y=df_remove['RainTomorrow']

mask=y.notna()
X_clean=X[mask].copy()
y_clean=y[mask].copy()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, shuffle=True, test_size=0.2, random_state=42)
X_train.shape, X_test.shape

from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer

imp = SimpleImputer(strategy='most_frequent')
cat_cols = [col for col in X_train.columns if X_train[col].dtype == 'object']
imp.fit(X_train[cat_cols])
X_train_cat_imp = imp.transform(X_train[cat_cols])
X_test_cat_imp = imp.transform(X_test[cat_cols])

X_train[cat_cols] = X_train_cat_imp
X_test[cat_cols] = X_test_cat_imp


num_cols = [col for col in X_train.columns if (X_train[col].dtype == 'int64' or X_train[col].dtype == 'float64')]
it = IterativeImputer(random_state=42)
it.fit(X_train[num_cols])
X_train_it = it.transform(X_train[num_cols])
X_test_it = it.transform(X_test[num_cols])

X_train[num_cols] = X_train_it
X_test[num_cols] = X_test_it

cols = ['WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']
for col in cols:
  data=df_remove[col].value_counts()
  plt.figure()
  plt.pie(data, labels = data.index, autopct='%1.1f%%')
  plt.show()

for col in X_train.columns:
  if X_train[col].dtype != 'object':
    plt.figure()
    sns.boxplot(X_train[col])
    plt.title(f'Ящик с усами для {col}')
    plt.show()

def iqr(X_train, X_test):
  train_clean = X_train.copy()
  test_clean = X_test.copy()
  columns = [col for col in X_train.columns if (X_train[col].dtype == 'int64' or X_train[col].dtype == 'float64')]
  for col in columns:
    Q1 = X_train[col].quantile(0.1)
    Q3 = X_train[col].quantile(0.9)
    IQR = Q3 - Q1
    lower = Q1 - 1.5*IQR
    upper = Q3 + 1.5*IQR

    train_clean[col] = np.clip(train_clean[col], lower, upper)
    test_clean[col] = np.clip(test_clean[col], lower, upper)

  return train_clean, test_clean

X_train_clean, X_test_clean = iqr(X_train, X_test)

X_train_clean.shape, X_test_clean.shape, y_train.shape, y_test.shape

columns = [col for col in X_train_clean.columns if (X_train_clean[col].dtype == 'int64' or X_train_clean[col].dtype == 'float64')]
plt.figure(figsize=(10,10))
df_selected = X_train_clean[columns]
corr = df_selected.corr(method='spearman')
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()

from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder

oe = OrdinalEncoder(categories=[['No', 'Yes']])
X_train_clean['RainToday'] = oe.fit_transform(X_train_clean[['RainToday']])
X_test_clean['RainToday'] = oe.transform(X_test_clean[['RainToday']])

# One-Hot Encoding
X_train_clean = pd.get_dummies(X_train_clean, columns=['WindGustDir', 'WindDir9am', 'WindDir3pm'], drop_first=True)
X_test_clean = pd.get_dummies(X_test_clean, columns=['WindGustDir', 'WindDir9am', 'WindDir3pm'], drop_first=True)

# Кодирование целевой переменной
y_train = oe.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test = oe.transform(y_test.values.reshape(-1, 1)).flatten()

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_clean)
X_test_scaled = scaler.transform(X_test_clean)

from sklearn.decomposition import PCA
pca = PCA(0.9)
X_train_pca = pca.fit_transform(X_train_scaled)
X_test_pca = pca.transform(X_test_scaled)

X_train_pca.shape, X_test_pca.shape

"""Модели для классификации"""

from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

"""Модели для регрессии"""

from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor

"""Метрики для классификации - accuracy, recall, f1
Метрики для регрессии - r2, mae, mape
"""

from sklearn.model_selection import cross_val_score
from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error
from sklearn.metrics import f1_score, recall_score, accuracy_score

def calculate_clf(y_true, y_pred):
  metrics = {
      'f1': f1_score(y_true, y_pred),
      'recall': recall_score(y_true, y_pred),
      'accuracy': accuracy_score(y_true, y_pred)
  }

  return metrics

def calculate_reg(y_true, y_pred):
  metrics = {
      'r2': r2_score(y_true, y_test),
      'mae': mean_absolute_error(y_true, y_test),
      'mape': mean_absolute_percentage_error(y_true,y_test)
  }

  return metrics

"""OPTUNA"""

pip install optuna

import optuna
def xgb_optimize_clf(X_train, y_train, X_test, y_test, n_trials=10):

  def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 150, 300),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),
        'n_jobs': -1,
        'random_state': 42
    }

    model = XGBClassifier(**params)
    score = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc', n_jobs=-1).mean()

    return score

  study = optuna.create_study(direction='maximize')
  study.optimize(objective, n_trials=n_trials)

  best_params = study.best_params
  best_xgb = XGBClassifier(**best_params, random_state=42)
  best_xgb.fit(X_train, y_train)

  y_pred = best_xgb.predict(X_test)
  metrics = calculate_clf(y_test, y_pred)
  print(f'Лучшие параметры: {best_params}')
  print(f'Accuracy: {metrics['accuracy']}')
  print(f'Recall: {metrics['recall']}')
  print(f'F1: {metrics['f1']}')

  return best_xgb, metrics, best_params


xgb_clf, xgb_metrics_clf, xgb_params = xgb_optimize_clf(X_train_pca, y_train, X_test_pca, y_test)

xgb_clf.fit(X_train_pca, y_train)
y_pred_xgb = xgb_clf.predict(X_test_pca)

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
cm = confusion_matrix(y_test, y_pred_xgb)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')

from sklearn.tree import DecisionTreeClassifier

# Простая модель для проверки
dt = DecisionTreeClassifier(max_depth=10, random_state=42)
dt.fit(X_train_pca, y_train)

y_pred_dt = dt.predict(X_test_pca)
accuracy_dt = f1_score(y_test, y_pred_dt)

print(f"Простое дерево Accuracy: {accuracy_dt:.4f}")

"""Параметры те же для рандомфореста и для для градиентного бустинга

Теперь для регрессии сделаем рандомфорест
"""

'''def rf_reg_optimize(X_train, y_train, X_test, y_test, n_trials=10):

  def objective(trial):
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 150),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'n_jobs': -1,
        'random_state': 42
    }

    model = RandomForestRegressor(**params)
    score = cross_val_score(model, X_train, y_train, cv=3, n_jobs=-1, scoring='r2').mean()
    return score

  study = optuna.create_study(direction='maximize')
  study.optimize(objective, n_trials=n_trials)

  best_params = study.best_params_
  best_rf = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)
  best_rf.fit(X_train, y_train)
  y_pred=best_rf.predict(X_test)

  metrics = calculate_reg(y_test, y_pred)
  print(f'Лучшие параметры: {best_params}')
  print(f'R2: {metrics['r2']}')
  print(f'MAE: {metrics['mae']}')
  print(f'MAPE: {metrics['mape']}')

  return best_rf, metrics, best_params

rf_reg, rf_metrics_reg, rf_params = rf_reg_optimize(X_train_pca, y_train, X_test_pca, y_test)'''



!pip install streamlit -q

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import streamlit as st
# import pandas as pd
# import numpy as np
# import matplotlib.pyplot as plt
# import seaborn as sns
# from sklearn.model_selection import train_test_split, cross_val_score
# from sklearn.experimental import enable_iterative_imputer
# from sklearn.impute import SimpleImputer, IterativeImputer
# from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder
# from sklearn.decomposition import PCA
# from sklearn.metrics import (accuracy_score, recall_score, f1_score, precision_score,
#                              confusion_matrix, ConfusionMatrixDisplay,
#                              roc_curve, auc, classification_report, roc_auc_score)
# import optuna
# from xgboost import XGBClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.linear_model import LogisticRegression
# from imblearn.over_sampling import SMOTE
# import warnings
# 
# warnings.filterwarnings('ignore')
# 
# # Настройка страницы
# st.set_page_config(
#     page_title="Dashboard - Классификация",
#     layout="wide"
# )
# 
# 
# # Функция загрузки данных
# @st.cache_data
# def load_data(uploaded_file=None):
#     if uploaded_file is not None:
#         try:
#             for encoding in ['utf-8', 'cp1251', 'latin1', 'ISO-8859-1']:
#                 try:
#                     df = pd.read_csv(uploaded_file, encoding=encoding)
#                     df = df.sample(50000, random_state=42)
#                     return df
#                 except:
#                     continue
#             df = pd.read_csv(uploaded_file, encoding='utf-8', errors='ignore')
#             df = df.sample(50000, random_state=42)
#             return df
#         except Exception as e:
#             st.error(f"Ошибка загрузки файла: {e}")
#             return None
#     else:
#         from sklearn.datasets import make_classification
#         X, y = make_classification(
#             n_samples=1000,
#             n_features=10,
#             n_classes=2,
#             weights=[0.8, 0.2],
#             random_state=42
#         )
#         feature_names = [f'feature_{i}' for i in range(10)]
#         df = pd.DataFrame(X, columns=feature_names)
#         df['target'] = y
#         return df
# 
# 
# # Основная функция
# def main():
#     st.title("Дашборд для классификации")
#     st.markdown("---")
# 
#     # Сайдбар
#     with st.sidebar:
#         st.header("Загрузка данных")
#         uploaded_file = st.file_uploader(
#             "Загрузите CSV файл",
#             type=['csv']
#         )
# 
#         st.header("Настройки")
#         target_col = st.text_input("Имя целевой переменной", "target")
# 
#         if st.button("Запустить анализ", type="primary", use_container_width=True):
#             st.session_state.run_analysis = True
#         else:
#             if 'run_analysis' not in st.session_state:
#                 st.session_state.run_analysis = False
# 
#         st.markdown("---")
#         st.markdown("**by Матросова Раиса**")
# 
#     # Вкладки
#     tab1, tab2 = st.tabs(["Предобработка+Визуализация", "Моделирование"])
# 
#     # Загрузка данных
#     df = load_data(uploaded_file)
# 
#     if df is None and uploaded_file is not None:
#         st.error("Не удалось загрузить данные")
#         return
# 
#     if df is not None:
#         # Вкладка 1: Предобработка и Визуализация
#         with tab1:
#             st.header("Предобработка данных")
# 
#             col1, col2 = st.columns(2)
#             with col1:
#                 st.metric("Количество строк", len(df))
#             with col2:
#                 st.metric("Количество столбцов", len(df.columns))
# 
#             # Просмотр данных
#             with st.expander("Просмотр данных", expanded=False):
#                 st.dataframe(df.head())
# 
#             # Проверка пропусков
#             if df.isnull().sum().sum() > 0:
#                 missing_df = pd.DataFrame({
#                     'Колонка': df.columns,
#                     'Пропуски': df.isnull().sum().values,
#                     '% Пропусков': (df.isnull().sum() / len(df) * 100).round(2)
#                 })
#                 st.dataframe(missing_df[missing_df['Пропуски'] > 0])
# 
#             # Разделение данных
#             if target_col in df.columns:
#                 # Кнопка предобработки с разделением логики
#                 if 'data_preprocessed' not in st.session_state:
#                     st.session_state.data_preprocessed = False
# 
#                 if not st.session_state.data_preprocessed:
#                     if st.button("Подготовить данные", type="secondary"):
#                         st.session_state.prepare_data = True
#                 else:
#                     st.success("Данные уже подготовлены!")
# 
#                 # Логика подготовки данных
#                 if 'prepare_data' in st.session_state and st.session_state.prepare_data:
#                     with st.spinner("Подготовка данных"):
#                         # Удаляем строки с пропусками в целевой переменной
#                         df_clean = df.copy()
#                         mask = df_clean[target_col].notna()
#                         df_clean = df_clean[mask].copy()
# 
#                         X = df_clean.drop(columns=[target_col])
#                         y = df_clean[target_col]
# 
#                         st.info(f"После удаления пропусков в целевой переменной: {len(df_clean)} строк")
# 
#                         # Кодирование целевой переменной если не числовая
#                         if y.dtype == 'object':
#                             le = LabelEncoder()
#                             y_encoded = le.fit_transform(y)
#                             st.success(
#                                 f"Целевая переменная закодирована: {list(le.classes_)} → {list(range(len(le.classes_)))}")
#                             st.session_state.label_encoder = le
#                         else:
#                             y_encoded = y.values
# 
#                         # Разделение
#                         X_train, X_test, y_train, y_test = train_test_split(
#                             X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
#                         )
# 
#                         st.info(f"Разделение: Train={X_train.shape}, Test={X_test.shape}")
# 
#                         # 1. Обработка пропусков в признаках
#                         # Категориальные признаки
#                         cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()
#                         if len(cat_cols) > 0:
#                             cat_imputer = SimpleImputer(strategy='most_frequent')
#                             X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])
#                             X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])
#                             st.success(f"Обработаны категориальные признаки: {len(cat_cols)}")
# 
#                         # Числовые признаки
#                         num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
#                         if len(num_cols) > 0:
#                             num_imputer = IterativeImputer(random_state=42, max_iter=10)
#                             X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])
#                             X_test[num_cols] = num_imputer.transform(X_test[num_cols])
#                             st.success(f"Обработаны числовые признаки: {len(num_cols)}")
# 
#                         # Сохраняем данные для визуализации в session_state
#                         st.session_state.X_for_viz = X.copy()
#                         st.session_state.cat_cols_viz = cat_cols.copy()
#                         st.session_state.num_cols_viz = num_cols.copy()
# 
#                         # Продолжаем предобработку
#                         # 2. Кодирование категориальных признаков
#                         if len(cat_cols) > 0:
#                             # Ordinal Encoding для бинарных категориальных признаков
#                             binary_cat_cols = []
#                             for col in cat_cols:
#                                 if X_train[col].nunique() == 2:
#                                     binary_cat_cols.append(col)
# 
#                             if binary_cat_cols:
#                                 oe = OrdinalEncoder()
#                                 for col in binary_cat_cols:
#                                     try:
#                                         X_train[col] = oe.fit_transform(X_train[[col]])
#                                         X_test[col] = oe.transform(X_test[[col]])
#                                     except:
#                                         le_col = LabelEncoder()
#                                         X_train[col] = le_col.fit_transform(X_train[col])
#                                         X_test[col] = le_col.transform(X_test[col])
# 
#                             # One-Hot Encoding для остальных категориальных
#                             non_binary_cat = [col for col in cat_cols if col not in binary_cat_cols]
#                             if non_binary_cat:
#                                 X_train = pd.get_dummies(X_train, columns=non_binary_cat, drop_first=True)
#                                 X_test = pd.get_dummies(X_test, columns=non_binary_cat, drop_first=True)
#                                 train_cols = X_train.columns
#                                 test_cols = X_test.columns
#                                 missing_cols = set(train_cols) - set(test_cols)
#                                 for col in missing_cols:
#                                     X_test[col] = 0
#                                 X_test = X_test[train_cols]
# 
#                         # 3. SMOTE балансировка
#                         smote = SMOTE(random_state=42)
#                         X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)
# 
#                         unique_before, counts_before = np.unique(y_train, return_counts=True)
#                         unique_after, counts_after = np.unique(y_train_resampled, return_counts=True)
# 
#                         st.success("SMOTE применен успешно!")
#                         st.write(f"До SMOTE: {dict(zip(unique_before, counts_before))}")
#                         st.write(f"После SMOTE: {dict(zip(unique_after, counts_after))}")
# 
#                         X_train = X_train_resampled
#                         y_train = y_train_resampled
# 
# 
#                         # 4. Удаление выбросов - IQR метод
#                         if len(num_cols) > 0:
#                             train_clean = X_train.copy()
#                             test_clean = X_test.copy()
# 
#                             for col in num_cols:
#                                 if col in train_clean.columns:
#                                     Q1 = train_clean[col].quantile(0.1)
#                                     Q3 = train_clean[col].quantile(0.9)
#                                     IQR = Q3 - Q1
#                                     lower = Q1 - 1.5 * IQR
#                                     upper = Q3 + 1.5 * IQR
# 
#                                     train_clean[col] = np.clip(train_clean[col], lower, upper)
#                                     if col in test_clean.columns:
#                                         test_clean[col] = np.clip(test_clean[col], lower, upper)
# 
#                             X_train = train_clean
#                             X_test = test_clean
# 
#                         # 5. Масштабирование
#                         if len(num_cols) > 0:
#                             scaler = StandardScaler()
#                             current_num_cols = [col for col in num_cols if col in X_train.columns]
#                             if current_num_cols:
#                                 X_train[current_num_cols] = scaler.fit_transform(X_train[current_num_cols])
#                                 X_test[current_num_cols] = scaler.transform(X_test[current_num_cols])
#                                 st.session_state.scaler = scaler
# 
#                         # 6. PCA если много признаков
#                         if X_train.shape[1] > 10:
#                             pca = PCA(n_components=0.9)
#                             X_train = pca.fit_transform(X_train)
#                             X_test = pca.transform(X_test)
#                             explained_variance = np.sum(pca.explained_variance_ratio_)
#                             st.success(
#                                 f"PCA применен: {X_train.shape[1]} компонент, объясненная дисперсия: {explained_variance:.2%}")
#                             st.session_state.pca = pca
# 
#                         # Сохраняем в session_state
#                         st.session_state.X_train = X_train
#                         st.session_state.X_test = X_test
#                         st.session_state.y_train = y_train
#                         st.session_state.y_test = y_test
#                         st.session_state.feature_names = X_train.columns.tolist() if hasattr(X_train, 'columns') else [
#                             f'feature_{i}' for i in range(X_train.shape[1])]
# 
#                         st.session_state.data_preprocessed = True
#                         st.session_state.prepare_data = False
# 
#                         st.success(f"Данные подготовлены. Train: {X_train.shape}, Test: {X_test.shape}")
# 
#                         # Показываем информацию о классах
#                         unique_classes, class_counts = np.unique(y_train, return_counts=True)
#                         st.subheader("Распределение классов в обучающих данных")
# 
#                         for cls, count in zip(unique_classes, class_counts):
#                             percentage = count / len(y_train) * 100
#                             st.write(f"Класс {cls}: {count} примеров ({percentage:.1f}%)")
# 
#                 if st.session_state.data_preprocessed:
#                     st.header("Визуализация данных")
# 
#                     # Получаем данные для визуализации из session_state
#                     X_for_viz = st.session_state.X_for_viz
#                     cat_cols = st.session_state.cat_cols_viz
#                     num_cols = st.session_state.num_cols_viz
# 
#                     # Создаем отдельные контейнеры для визуализаций
#                     viz_container = st.container()
# 
#                     with viz_container:
#                         # Круговые диаграммы для категориальных признаков
#                         if len(cat_cols) > 0:
#                             st.subheader("Круговые диаграммы для категориальных признаков")
#                             selected_cat = st.selectbox("Выберите признак",
#                                                         cat_cols[:min(5, len(cat_cols))],
#                                                         key='cat_select')
# 
#                             if selected_cat in X_for_viz.columns:
#                                 value_counts = X_for_viz[selected_cat].value_counts().head(10)
#                                 fig, ax = plt.subplots(figsize=(8, 6))
#                                 ax.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
#                                 ax.set_title(f"Распределение: {selected_cat}")
#                                 st.pyplot(fig)
# 
#                         # Распределение для числовых признаков
#                         if len(num_cols) > 0:
#                             st.subheader("Распределение числовых признаков")
#                             selected_num = st.selectbox("Выберите признак",
#                                                         num_cols[:min(5, len(num_cols))],
#                                                         key='num_select')
#                             if selected_num in X_for_viz.columns:
#                                 fig, ax = plt.subplots(figsize=(8, 5))
#                                 ax.hist(X_for_viz[selected_num].dropna(), bins=30, edgecolor='black', alpha=0.7)
#                                 ax.set_title(f"Распределение: {selected_num}")
#                                 ax.set_xlabel(selected_num)
#                                 ax.set_ylabel("Частота")
#                                 ax.grid(True, alpha=0.3)
#                                 st.pyplot(fig)
# 
#                         # Ящик с усами для числовых признаков
#                         if len(num_cols) > 0:
#                             st.subheader("Boxplot для числовых признаков")
#                             selected_box = st.multiselect(
#                                 "Выберите признаки",
#                                 num_cols[:min(5, len(num_cols))],
#                                 default=num_cols[:min(3, len(num_cols))],
#                                 key='box_select'
#                             )
#                             if selected_box:
#                                 fig, ax = plt.subplots(figsize=(10, 6))
#                                 data_to_plot = [X_for_viz[col].dropna() for col in selected_box]
#                                 ax.boxplot(data_to_plot, labels=selected_box)
#                                 ax.set_title("Boxplot выбранных признаков")
#                                 ax.set_ylabel("Значения")
#                                 ax.grid(True, alpha=0.3)
#                                 plt.xticks(rotation=45)
#                                 st.pyplot(fig)
# 
#                         # Парные графики (scatter plot)
#                         if len(num_cols) >= 2:
#                             st.subheader("Парные отношения признаков")
#                             col1 = st.selectbox("Первый признак", num_cols, key='pair1')
#                             col2 = st.selectbox("Второй признак", [c for c in num_cols if c != col1], key='pair2')
# 
#                             fig, ax = plt.subplots(figsize=(8, 6))
#                             scatter = ax.scatter(X_for_viz[col1], X_for_viz[col2], alpha=0.5, s=20)
#                             ax.set_xlabel(col1)
#                             ax.set_ylabel(col2)
#                             ax.set_title(f'Парные отношения: {col1} vs {col2}')
#                             ax.grid(True, alpha=0.3)
#                             st.pyplot(fig)
# 
#                         # Корреляционная матрица
#                         if len(num_cols) > 1:
#                             st.subheader("Корреляционная матрица")
#                             fig, ax = plt.subplots(figsize=(10, 8))
#                             corr_matrix = X_for_viz[num_cols].corr()
#                             sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
#                                         center=0, ax=ax, square=True, cbar_kws={"shrink": 0.8})
#                             ax.set_title('Корреляционная матрица числовых признаков')
#                             st.pyplot(fig)
#             else:
#                 st.error(f"Целевая переменная '{target_col}' не найдена")
# 
#         # Вкладка 2: Моделирование
#         with tab2:
#             st.header("Моделирование")
# 
#             if 'X_train' in st.session_state:
#                 X_train = st.session_state.X_train
#                 X_test = st.session_state.X_test
#                 y_train = st.session_state.y_train
#                 y_test = st.session_state.y_test
#                 feature_names = st.session_state.feature_names
# 
#                 # Выбор модели
#                 model_choice = st.selectbox(
#                     "Выберите модель",
#                     ["XGBoost", "Random Forest", "Logistic Regression"]
#                 )
# 
#                 # Настройки Optuna
#                 n_trials = st.slider("Количество испытаний Optuna", 5, 30, 10)
# 
#                 if st.button("Обучить модель", type="primary", use_container_width=True):
#                     with st.spinner("Обучение модели с помощью Optuna"):
#                         # Функция для Optuna
#                         def objective(trial):
#                             if model_choice == "XGBoost":
#                                 params = {
#                                     'n_estimators': trial.suggest_int('n_estimators', 50, 300),
#                                     'max_depth': trial.suggest_int('max_depth', 3, 10),
#                                     'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
#                                     'subsample': trial.suggest_float('subsample', 0.6, 1.0),
#                                     'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
#                                     'random_state': 42
#                                 }
#                                 model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')
# 
#                             elif model_choice == "Random Forest":
#                                 params = {
#                                     'n_estimators': trial.suggest_int('n_estimators', 50, 300),
#                                     'max_depth': trial.suggest_int('max_depth', 3, 20),
#                                     'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
#                                     'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
#                                     'random_state': 42
#                                 }
#                                 model = RandomForestClassifier(**params)
# 
#                             else:  # Logistic Regression
#                                 params = {
#                                     'C': trial.suggest_float('C', 0.01, 10.0, log=True),
#                                     'max_iter': trial.suggest_int('max_iter', 100, 1000),
#                                     'random_state': 42
#                                 }
#                                 model = LogisticRegression(**params)
# 
#                             score = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc').mean()
#                             return score
# 
#                         # Запуск Optuna
#                         study = optuna.create_study(direction='maximize')
#                         study.optimize(objective, n_trials=n_trials, show_progress_bar=False)
# 
#                         # Лучшие параметры
#                         best_params = study.best_params
#                         st.success(f"Лучшие параметры: {best_params}")
# 
#                         # Создание и обучение модели с лучшими параметрами
#                         if model_choice == "XGBoost":
#                             model = XGBClassifier(**best_params, use_label_encoder=False,
#                                                   eval_metric='logloss', random_state=42)
#                         elif model_choice == "Random Forest":
#                             model = RandomForestClassifier(**best_params, random_state=42)
#                         else:
#                             model = LogisticRegression(**best_params, random_state=42)
# 
#                         model.fit(X_train, y_train)
# 
#                         # Предсказания
#                         y_pred = model.predict(X_test)
#                         y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None
# 
#                         # Метрики
#                         st.subheader("Метрики модели")
# 
#                         col1, col2, col3, col4 = st.columns(4)
#                         with col1:
#                             accuracy = accuracy_score(y_test, y_pred)
#                             st.metric("Accuracy", f"{accuracy:.3f}")
#                         with col2:
#                             precision = precision_score(y_test, y_pred, average='weighted')
#                             st.metric("Precision", f"{precision:.3f}")
#                         with col3:
#                             recall = recall_score(y_test, y_pred, average='weighted')
#                             st.metric("Recall", f"{recall:.3f}")
#                         with col4:
#                             f1 = f1_score(y_test, y_pred, average='weighted')
#                             st.metric("F1-Score", f"{f1:.3f}")
# 
#                         # ROC-AUC
#                         if y_pred_proba is not None:
#                             try:
#                                 roc_auc = roc_auc_score(y_test, y_pred_proba)
#                                 st.metric("ROC-AUC", f"{roc_auc:.3f}")
#                             except:
#                                 pass
# 
#                         # Примеры предсказаний
#                         st.subheader("Примеры предсказаний")
#                         n_samples = min(5, len(X_test))
#                         sample_indices = np.random.choice(len(X_test), n_samples, replace=False)
# 
#                         predictions_df = pd.DataFrame({
#                             'Фактический': y_test[sample_indices],
#                             'Предсказанный': y_pred[sample_indices]
#                         })
# 
#                         st.dataframe(predictions_df)
# 
#                         # График ошибок
#                         st.subheader("Матрица ошибок")
#                         fig, ax = plt.subplots(figsize=(6, 5))
#                         cm = confusion_matrix(y_test, y_pred)
#                         disp = ConfusionMatrixDisplay(confusion_matrix=cm)
#                         disp.plot(ax=ax, cmap='Blues')
#                         ax.set_title("Матрица ошибок")
#                         st.pyplot(fig)
# 
#                         # ROC-кривая
#                         if y_pred_proba is not None:
#                             st.subheader("ROC-кривая")
#                             fig, ax = plt.subplots(figsize=(6, 5))
#                             fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
#                             roc_auc = auc(fpr, tpr)
# 
#                             ax.plot(fpr, tpr, color='darkorange', lw=2,
#                                     label=f'ROC curve (AUC = {roc_auc:.3f})')
#                             ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
#                             ax.set_xlim([0.0, 1.0])
#                             ax.set_ylim([0.0, 1.05])
#                             ax.set_xlabel('False Positive Rate')
#                             ax.set_ylabel('True Positive Rate')
#                             ax.set_title('ROC Curve')
#                             ax.legend(loc="lower right")
#                             ax.grid(True, alpha=0.3)
#                             st.pyplot(fig)
# 
#                         # Отчет по классификации
#                         st.subheader("Отчет по классификации")
#                         report = classification_report(y_test, y_pred, output_dict=True)
#                         report_df = pd.DataFrame(report).transpose()
#                         st.dataframe(report_df.style.format("{:.3f}"))
# 
#             else:
#                 st.info("Сначала подготовьте данные на вкладке 'Предобработка'")
#     else:
#         st.info("Загрузите CSV файл или используйте демо-данные для начала работы")
# 
# 
# if __name__ == "__main__":
#     main()

import subprocess
import threading

# Function to run the Streamlit app
def run_streamlit():
    subprocess.run(["streamlit", "run", "app.py"])

# Run Streamlit app in a separate thread
thread = threading.Thread(target=run_streamlit)
thread.start()
# Create a tunnel using serveo.net
!ssh -o StrictHostKeyChecking=no -R 80:localhost:8501 serveo.net



import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, IterativeImputer
from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error
import optuna
from xgboost import XGBRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import warnings
import shap

warnings.filterwarnings('ignore')

# Настройка страницы
st.set_page_config(
    page_title="Dashboard - Регрессия",
    layout="wide"
)


# Функция загрузки данных
@st.cache_data
def load_data(uploaded_file=None):
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file, sep=';')

        # Если слишком много строк, делаем выборку
        if len(df) > 50000:
            df = df.sample(50000, random_state=42)

        return df

    else:
        # Демо-данные для регрессии
        np.random.seed(42)
        n_samples = 1000

        # Генерация признаков
        size = np.random.normal(150, 50, n_samples)
        bedrooms = np.random.randint(1, 6, n_samples)
        age = np.random.randint(0, 50, n_samples)
        location = np.random.choice(['A', 'B', 'C'], n_samples, p=[0.5, 0.3, 0.2])

        # Генерация целевой переменной (цена)
        price = (
                30000 * np.clip(size, 50, 300) +
                50000 * bedrooms +
                (-20000 * np.clip(age, 0, 100)) +
                np.random.normal(0, 50000, n_samples)
        )

        # Добавление эффекта локации
        price = np.where(location == 'A', price * 1.2,
                         np.where(location == 'B', price * 1.1, price))

        df = pd.DataFrame({
            'size': np.clip(size, 50, 300),
            'bedrooms': bedrooms,
            'age': np.clip(age, 0, 100),
            'location': location,
            'price': np.clip(price, 100000, 1000000)
        })
        return df


# Основная функция
def main():
    st.title("Дашборд для регрессии")
    st.markdown("---")

    # Сайдбар
    with st.sidebar:
        st.header("Загрузка данных")
        uploaded_file = st.file_uploader(
            "Загрузите CSV файл",
            type=['csv']
        )

        st.header("Настройки")
        target_col = st.text_input("Имя целевой переменной", "price")

        if st.button("Запустить анализ", type="primary", use_container_width=True):
            st.session_state.run_analysis = True
        else:
            if 'run_analysis' not in st.session_state:
                st.session_state.run_analysis = False

        st.markdown("---")
        st.markdown("**by Матросова Раиса**")

    # Вкладки
    tab1, tab2 = st.tabs(["Предобработка+Визуализация", "Моделирование"])

    # Загрузка данных
    df = load_data(uploaded_file)

    if df is None and uploaded_file is not None:
        st.error("Не удалось загрузить данные")
        return

    if df is not None:
        # Вкладка 1: Предобработка и Визуализация
        with tab1:
            st.header("Предобработка данных")

            col1, col2 = st.columns(2)
            with col1:
                st.metric("Количество строк", len(df))
            with col2:
                st.metric("Количество столбцов", len(df.columns))

            # Просмотр данных
            with st.expander("Просмотр данных", expanded=False):
                st.dataframe(df.head())

            # Проверка пропусков
            if df.isnull().sum().sum() > 0:
                missing_df = pd.DataFrame({
                    'Колонка': df.columns,
                    'Пропуски': df.isnull().sum().values,
                    '% Пропусков': (df.isnull().sum() / len(df) * 100).round(2)
                })
                st.dataframe(missing_df[missing_df['Пропуски'] > 0])

            # Разделение данных
            if target_col in df.columns:
                # Кнопка предобработки с разделением логики
                if 'data_preprocessed' not in st.session_state:
                    st.session_state.data_preprocessed = False

                if not st.session_state.data_preprocessed:
                    if st.button("Подготовить данные", type="secondary"):
                        st.session_state.prepare_data = True
                else:
                    st.success("Данные уже подготовлены!")

                # Логика подготовки данных
                if 'prepare_data' in st.session_state and st.session_state.prepare_data:
                    with st.spinner("Подготовка данных"):
                        # Удаляем строки с пропусками в целевой переменной
                        df_clean = df.copy()
                        mask = df_clean[target_col].notna()
                        df_clean = df_clean[mask].copy()

                        X = df_clean.drop(columns=[target_col])
                        y = df_clean[target_col]

                        st.info(f"После удаления пропусков в целевой переменной: {len(df_clean)} строк")

                        # Проверка типа целевой переменной
                        if y.dtype == 'object':
                            try:
                                y = pd.to_numeric(y, errors='coerce')
                                mask = y.notna()
                                X = X[mask].copy()
                                y = y[mask].copy()
                                st.success("Целевая переменная преобразована в числовой формат")
                            except:
                                st.error("Не удалось преобразовать целевую переменную в числовой формат")
                                return

                        # Разделение
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42
                        )

                        st.info(f"Разделение: Train={X_train.shape}, Test={X_test.shape}")

                        # 1. Обработка пропусков в признаках
                        # Категориальные признаки
                        cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()
                        if len(cat_cols) > 0:
                            cat_imputer = SimpleImputer(strategy='most_frequent')
                            X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])
                            X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])
                            st.success(f"Обработаны категориальные признаки: {len(cat_cols)}")

                        # Числовые признаки
                        num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
                        if len(num_cols) > 0:
                            num_imputer = IterativeImputer(random_state=42, max_iter=10)
                            X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])
                            X_test[num_cols] = num_imputer.transform(X_test[num_cols])
                            st.success(f"Обработаны числовые признаки: {len(num_cols)}")

                        # Сохраняем данные для визуализации в session_state
                        st.session_state.X_for_viz = X.copy()
                        st.session_state.y_for_viz = y.copy()
                        st.session_state.cat_cols_viz = cat_cols.copy()
                        st.session_state.num_cols_viz = num_cols.copy()

                        # Продолжаем предобработку
                        # 2. Кодирование категориальных признаков
                        if len(cat_cols) > 0:
                            # Ordinal Encoding для бинарных категориальных признаков
                            binary_cat_cols = []
                            for col in cat_cols:
                                if X_train[col].nunique() == 2:
                                    binary_cat_cols.append(col)

                            if binary_cat_cols:
                                oe = OrdinalEncoder()
                                for col in binary_cat_cols:
                                    try:
                                        X_train[col] = oe.fit_transform(X_train[[col]])
                                        X_test[col] = oe.transform(X_test[[col]])
                                    except:
                                        le_col = LabelEncoder()
                                        X_train[col] = le_col.fit_transform(X_train[col])
                                        X_test[col] = le_col.transform(X_test[col])

                            # One-Hot Encoding для остальных категориальных
                            non_binary_cat = [col for col in cat_cols if col not in binary_cat_cols]
                            if non_binary_cat:
                                X_train = pd.get_dummies(X_train, columns=non_binary_cat, drop_first=True)
                                X_test = pd.get_dummies(X_test, columns=non_binary_cat, drop_first=True)
                                train_cols = X_train.columns
                                test_cols = X_test.columns
                                missing_cols = set(train_cols) - set(test_cols)
                                for col in missing_cols:
                                    X_test[col] = 0
                                X_test = X_test[train_cols]

                        # 3. Удаление выбросов - IQR метод
                        if len(num_cols) > 0:
                            train_clean = X_train.copy()
                            test_clean = X_test.copy()

                            for col in num_cols:
                                if col in train_clean.columns:
                                    Q1 = train_clean[col].quantile(0.1)
                                    Q3 = train_clean[col].quantile(0.9)
                                    IQR = Q3 - Q1
                                    lower = Q1 - 1.5 * IQR
                                    upper = Q3 + 1.5 * IQR

                                    train_clean[col] = np.clip(train_clean[col], lower, upper)
                                    if col in test_clean.columns:
                                        test_clean[col] = np.clip(test_clean[col], lower, upper)

                            X_train = train_clean
                            X_test = test_clean

                        # 4. Масштабирование
                        if len(num_cols) > 0:
                            scaler = StandardScaler()
                            current_num_cols = [col for col in num_cols if col in X_train.columns]
                            if current_num_cols:
                                X_train[current_num_cols] = scaler.fit_transform(X_train[current_num_cols])
                                X_test[current_num_cols] = scaler.transform(X_test[current_num_cols])
                                st.session_state.scaler = scaler

                        # 5. PCA если много признаков
                        if X_train.shape[1] > 10:
                            pca = PCA(n_components=0.9)
                            X_train = pca.fit_transform(X_train)
                            X_test = pca.transform(X_test)
                            explained_variance = np.sum(pca.explained_variance_ratio_)
                            st.success(
                                f"PCA применен: {X_train.shape[1]} компонент, объясненная дисперсия: {explained_variance:.2%}")
                            st.session_state.pca = pca

                        # Сохраняем в session_state
                        st.session_state.X_train = X_train
                        st.session_state.X_test = X_test
                        st.session_state.y_train = y_train.values
                        st.session_state.y_test = y_test.values
                        st.session_state.feature_names = X_train.columns.tolist() if hasattr(X_train, 'columns') else [
                            f'feature_{i}' for i in range(X_train.shape[1])]

                        st.session_state.data_preprocessed = True
                        st.session_state.prepare_data = False

                        st.success(f"Данные подготовлены. Train: {X_train.shape}, Test: {X_test.shape}")

                        # Статистика по целевой переменной
                        st.subheader("Статистика целевой переменной")
                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            st.metric("Среднее", f"{y.mean():.2f}")
                        with col2:
                            st.metric("Стандартное отклонение", f"{y.std():.2f}")
                        with col3:
                            st.metric("Минимум", f"{y.min():.2f}")
                        with col4:
                            st.metric("Максимум", f"{y.max():.2f}")

                if st.session_state.data_preprocessed:
                    st.header("Визуализация данных")

                    # Получаем данные для визуализации из session_state
                    X_for_viz = st.session_state.X_for_viz
                    y_for_viz = st.session_state.y_for_viz
                    cat_cols = st.session_state.cat_cols_viz
                    num_cols = st.session_state.num_cols_viz

                    # Создаем отдельные контейнеры для визуализаций
                    viz_container = st.container()

                    with viz_container:
                        # Круговые диаграммы для категориальных признаков
                        if len(cat_cols) > 0:
                            st.subheader("Круговые диаграммы для категориальных признаков")
                            selected_cat = st.selectbox("Выберите признак",
                                                        cat_cols[:min(5, len(cat_cols))],
                                                        key='cat_select')

                            if selected_cat in X_for_viz.columns:
                                value_counts = X_for_viz[selected_cat].value_counts().head(10)
                                fig, ax = plt.subplots(figsize=(8, 6))
                                ax.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
                                ax.set_title(f"Распределение: {selected_cat}")
                                st.pyplot(fig)

                        # Распределение для числовых признаков
                        if len(num_cols) > 0:
                            st.subheader("Распределение числовых признаков")
                            selected_num = st.selectbox("Выберите признак",
                                                        num_cols[:min(5, len(num_cols))],
                                                        key='num_select')
                            if selected_num in X_for_viz.columns:
                                fig, ax = plt.subplots(figsize=(8, 5))
                                ax.hist(X_for_viz[selected_num].dropna(), bins=30, edgecolor='black', alpha=0.7)
                                ax.set_title(f"Распределение: {selected_num}")
                                ax.set_xlabel(selected_num)
                                ax.set_ylabel("Частота")
                                ax.grid(True, alpha=0.3)
                                st.pyplot(fig)

                        # Ящик с усами для числовых признаков
                        if len(num_cols) > 0:
                            st.subheader("Boxplot для числовых признаков")
                            selected_box = st.multiselect(
                                "Выберите признаки",
                                num_cols[:min(5, len(num_cols))],
                                default=num_cols[:min(3, len(num_cols))],
                                key='box_select'
                            )
                            if selected_box:
                                fig, ax = plt.subplots(figsize=(10, 6))
                                data_to_plot = [X_for_viz[col].dropna() for col in selected_box]
                                ax.boxplot(data_to_plot, labels=selected_box)
                                ax.set_title("Boxplot выбранных признаков")
                                ax.set_ylabel("Значения")
                                ax.grid(True, alpha=0.3)
                                plt.xticks(rotation=45)
                                st.pyplot(fig)

                        # Парные графики (scatter plot)
                        if len(num_cols) >= 2:
                            st.subheader("Парные отношения признаков")
                            col1 = st.selectbox("Первый признак", num_cols, key='pair1')
                            col2 = st.selectbox("Второй признак", [c for c in num_cols if c != col1], key='pair2')

                            fig, ax = plt.subplots(figsize=(8, 6))
                            scatter = ax.scatter(X_for_viz[col1], X_for_viz[col2], alpha=0.5, s=20)
                            ax.set_xlabel(col1)
                            ax.set_ylabel(col2)
                            ax.set_title(f'Парные отношения: {col1} vs {col2}')
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)

                        # Корреляционная матрица
                        if len(num_cols) > 1:
                            st.subheader("Корреляционная матрица")

                            # Создаем DataFrame с числовыми признаками и целевой переменной
                            numeric_data = pd.concat([X_for_viz[num_cols], pd.Series(y_for_viz, name=target_col)],
                                                     axis=1)

                            fig, ax = plt.subplots(figsize=(10, 8))
                            corr_matrix = numeric_data.corr()
                            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
                                        center=0, ax=ax, square=True, cbar_kws={"shrink": 0.8})
                            ax.set_title('Корреляционная матрица числовых признаков')
                            st.pyplot(fig)

                            # Корреляции с целевой переменной
                            st.subheader("Корреляции с целевой переменной")
                            target_corr = corr_matrix[target_col].drop(target_col).sort_values(key=abs, ascending=False)

                            fig, ax = plt.subplots(figsize=(10, 6))
                            colors = ['red' if x < 0 else 'green' for x in target_corr.values]
                            ax.barh(range(len(target_corr)), target_corr.values, color=colors)
                            ax.set_yticks(range(len(target_corr)))
                            ax.set_yticklabels(target_corr.index)
                            ax.set_xlabel('Корреляция')
                            ax.set_title(f'Корреляция признаков с {target_col}')
                            ax.grid(True, alpha=0.3, axis='x')
                            st.pyplot(fig)
            else:
                st.error(f"Целевая переменная '{target_col}' не найдена")

        # Вкладка 2: Моделирование
        with tab2:
            st.header("Моделирование")

            if 'X_train' in st.session_state:
                X_train = st.session_state.X_train
                X_test = st.session_state.X_test
                y_train = st.session_state.y_train
                y_test = st.session_state.y_test
                feature_names = st.session_state.feature_names

                # Выбор модели
                model_choice = st.selectbox(
                    "Выберите модель",
                    ["XGBoost", "Random Forest", "Linear Regression"]
                )

                # Настройки Optuna (перенесены на страницу моделирования)
                n_trials = st.slider("Количество испытаний Optuna", 5, 30, 10)

                if st.button("Обучить модель", type="primary", use_container_width=True):
                    with st.spinner("Обучение модели с помощью Optuna"):
                        # Функция для Optuna
                        def objective(trial):
                            if model_choice == "XGBoost":
                                params = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                                    'max_depth': trial.suggest_int('max_depth', 3, 10),
                                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                                    'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),
                                    'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),
                                    'random_state': 42
                                }
                                model = XGBRegressor(**params)

                            elif model_choice == "Random Forest":
                                params = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                                    'max_depth': trial.suggest_int('max_depth', 3, 20),
                                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                                    'random_state': 42
                                }
                                model = RandomForestRegressor(**params)

                            else:  # Linear Regression
                                # Для Linear Regression не настраиваем параметры через Optuna
                                model = LinearRegression()
                                # Возвращаем фиксированное значение для завершения trial
                                score = cross_val_score(model, X_train, y_train, cv=3, scoring='r2').mean()
                                return score

                            if model_choice != "Linear Regression":
                                score = cross_val_score(model, X_train, y_train, cv=3, scoring='r2').mean()
                            return score

                        # Запуск Optuna
                        if model_choice == "Linear Regression":
                            # Для Linear Regression не используем Optuna
                            best_params = {}
                            model = LinearRegression()
                        else:
                            study = optuna.create_study(direction='maximize')
                            study.optimize(objective, n_trials=n_trials, show_progress_bar=False)

                            # Лучшие параметры
                            best_params = study.best_params
                            st.success(f"Лучшие параметры: {best_params}")

                            # Создание и обучение модели с лучшими параметрами
                            if model_choice == "XGBoost":
                                model = XGBRegressor(**best_params, random_state=42)
                            elif model_choice == "Random Forest":
                                model = RandomForestRegressor(**best_params, random_state=42)

                        model.fit(X_train, y_train)

                        # Предсказания
                        y_pred = model.predict(X_test)

                        # Метрики регрессии
                        st.subheader("Метрики модели")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            mae = mean_absolute_error(y_test, y_pred)
                            st.metric("MAE", f"{mae:.3f}")
                        with col2:
                            mape = mean_absolute_percentage_error(y_test, y_pred)
                            st.metric("MAPE", f"{mape:.3%}")
                        with col3:
                            mse = mean_squared_error(y_test, y_pred)
                            rmse = np.sqrt(mse)
                            st.metric("RMSE", f"{rmse:.3f}")
                        with col4:
                            r2 = r2_score(y_test, y_pred)
                            st.metric("R² Score", f"{r2:.3f}")


                        # Примеры предсказаний
                        st.subheader("Примеры предсказаний")
                        n_samples = min(5, len(X_test))
                        sample_indices = np.random.choice(len(X_test), n_samples, replace=False)

                        predictions_df = pd.DataFrame({
                            'Фактическое': y_test[sample_indices],
                            'Предсказанное': y_pred[sample_indices],
                            'Ошибка': y_test[sample_indices] - y_pred[sample_indices]
                        }).round(2)

                        st.dataframe(predictions_df)

                        # График фактических vs предсказанных значений
                        st.subheader("Фактические vs Предсказанные значения")
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.scatter(y_test, y_pred, alpha=0.5, s=20)

                        # Линия идеального предсказания
                        min_val = min(y_test.min(), y_pred.min())
                        max_val = max(y_test.max(), y_pred.max())
                        ax.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Идеальное предсказание')

                        ax.set_xlabel('Фактические значения')
                        ax.set_ylabel('Предсказанные значения')
                        ax.set_title('Фактические vs Предсказанные значения')
                        ax.legend()
                        ax.grid(True, alpha=0.3)
                        st.pyplot(fig)


                        # SHAP анализ
                        st.subheader("SHAP анализ")

                        try:
                            # Используем подвыборку для ускорения расчета
                            sample_size = min(100, X_train.shape[0])
                            if hasattr(X_train, 'iloc'):
                                X_sample = X_train.iloc[:sample_size]
                            else:
                                X_sample = X_train[:sample_size]

                            # Выбор объяснителя в зависимости от модели
                            if model_choice in ["XGBoost", "Random Forest"]:
                                explainer = shap.TreeExplainer(model)
                                shap_values = explainer.shap_values(X_sample)
                            else:
                                # Для линейных моделей используем KernelExplainer
                                explainer = shap.KernelExplainer(model.predict, X_sample)
                                shap_values = explainer.shap_values(X_sample)

                            # Summary plot
                            st.write("**Summary Plot**")
                            fig, ax = plt.subplots(figsize=(12, 8))
                            shap.summary_plot(shap_values, X_sample,
                                              feature_names=feature_names[:X_sample.shape[1]],
                                              show=False, max_display=20)
                            plt.tight_layout()
                            st.pyplot(fig)

                            # Bar plot
                            st.write("**Bar Plot (Средние абсолютные SHAP значения)**")
                            fig, ax = plt.subplots(figsize=(12, 8))
                            shap.summary_plot(shap_values, X_sample,
                                              feature_names=feature_names[:X_sample.shape[1]],
                                              plot_type="bar", show=False, max_display=20)
                            plt.tight_layout()
                            st.pyplot(fig)

                        except Exception as e:
                            st.error(f"Ошибка при расчете SHAP значений: {e}")
                            st.info("SHAP анализ может быть недоступен для некоторых типов моделей или данных")

            else:
                st.info("Сначала подготовьте данные на вкладке 'Предобработка'")
    else:
        st.info("Загрузите CSV файл или используйте демо-данные для начала работы")


if __name__ == "__main__":
    main()



import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, IterativeImputer
from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder
from sklearn.decomposition import PCA
from sklearn.metrics import (accuracy_score, recall_score, f1_score, precision_score,
                             confusion_matrix, ConfusionMatrixDisplay,
                             roc_curve, auc, classification_report, roc_auc_score)
import optuna
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import SMOTE
import warnings

warnings.filterwarnings('ignore')

# Настройка страницы
st.set_page_config(
    page_title="Dashboard - Классификация",
    layout="wide"
)


# Функция загрузки данных
@st.cache_data
def load_data(uploaded_file=None):
    if uploaded_file is not None:
        try:
            for encoding in ['utf-8', 'cp1251', 'latin1', 'ISO-8859-1']:
                try:
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    df = df.sample(50000, random_state=42)
                    return df
                except:
                    continue
            df = pd.read_csv(uploaded_file, encoding='utf-8')
            df = df.sample(50000, random_state=42)
            return df
        except Exception as e:
            st.error(f"Ошибка загрузки файла: {e}")
            return None
    else:
        from sklearn.datasets import make_classification
        X, y = make_classification(
            n_samples=1000,
            n_features=10,
            n_classes=2,
            weights=[0.8, 0.2],
            random_state=42
        )
        feature_names = [f'feature_{i}' for i in range(10)]
        df = pd.DataFrame(X, columns=feature_names)
        df['target'] = y
        return df


# Основная функция
def main():
    st.title("Дашборд для классификации")
    st.markdown("---")

    # Сайдбар
    with st.sidebar:
        st.header("Загрузка данных")
        uploaded_file = st.file_uploader(
            "Загрузите CSV файл",
            type=['csv']
        )

        st.header("Настройки")
        target_col = st.text_input("Имя целевой переменной", "target")

        if st.button("Запустить анализ", type="primary", use_container_width=True):
            st.session_state.run_analysis = True
        else:
            if 'run_analysis' not in st.session_state:
                st.session_state.run_analysis = False

        st.markdown("---")
        st.markdown("**by Матросова Раиса**")

    # Вкладки
    tab1, tab2 = st.tabs(["Предобработка+Визуализация", "Моделирование"])

    # Загрузка данных
    df = load_data(uploaded_file)

    if df is None and uploaded_file is not None:
        st.error("Не удалось загрузить данные")
        return

    if df is not None:
        # Вкладка 1: Предобработка и Визуализация
        with tab1:
            st.header("Предобработка данных")

            col1, col2 = st.columns(2)
            with col1:
                st.metric("Количество строк", len(df))
            with col2:
                st.metric("Количество столбцов", len(df.columns))

            # Просмотр данных
            with st.expander("Просмотр данных", expanded=False):
                st.dataframe(df.head())

            # Проверка пропусков
            if df.isnull().sum().sum() > 0:
                missing_df = pd.DataFrame({
                    'Колонка': df.columns,
                    'Пропуски': df.isnull().sum().values,
                    '% Пропусков': (df.isnull().sum() / len(df) * 100).round(2)
                })
                st.dataframe(missing_df[missing_df['Пропуски'] > 0])

            # Разделение данных
            if target_col in df.columns:
                # Кнопка предобработки с разделением логики
                if 'data_preprocessed' not in st.session_state:
                    st.session_state.data_preprocessed = False

                if not st.session_state.data_preprocessed:
                    if st.button("Подготовить данные", type="secondary"):
                        st.session_state.prepare_data = True
                else:
                    st.success("Данные уже подготовлены!")

                # Логика подготовки данных
                if 'prepare_data' in st.session_state and st.session_state.prepare_data:
                    with st.spinner("Подготовка данных"):
                        # Удаляем строки с пропусками в целевой переменной
                        df_clean = df.copy()
                        mask = df_clean[target_col].notna()
                        df_clean = df_clean[mask].copy()

                        X = df_clean.drop(columns=[target_col])
                        y = df_clean[target_col]

                        st.info(f"После удаления пропусков в целевой переменной: {len(df_clean)} строк")

                        # Кодирование целевой переменной если не числовая
                        if y.dtype == 'object':
                            le = LabelEncoder()
                            y_encoded = le.fit_transform(y)
                            st.success(
                                f"Целевая переменная закодирована: {list(le.classes_)} → {list(range(len(le.classes_)))}")
                            st.session_state.label_encoder = le
                        else:
                            y_encoded = y.values

                        # Разделение
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
                        )

                        st.info(f"Разделение: Train={X_train.shape}, Test={X_test.shape}")

                        # 1. Обработка пропусков в признаках
                        # Категориальные признаки
                        cat_cols = X_train.select_dtypes(include=['object']).columns.tolist()
                        if len(cat_cols) > 0:
                            cat_imputer = SimpleImputer(strategy='most_frequent')
                            X_train[cat_cols] = cat_imputer.fit_transform(X_train[cat_cols])
                            X_test[cat_cols] = cat_imputer.transform(X_test[cat_cols])
                            st.success(f"Обработаны категориальные признаки: {len(cat_cols)}")

                        # Числовые признаки
                        num_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()
                        if len(num_cols) > 0:
                            num_imputer = IterativeImputer(random_state=42, max_iter=10)
                            X_train[num_cols] = num_imputer.fit_transform(X_train[num_cols])
                            X_test[num_cols] = num_imputer.transform(X_test[num_cols])
                            st.success(f"Обработаны числовые признаки: {len(num_cols)}")

                        # Сохраняем данные для визуализации в session_state
                        st.session_state.X_for_viz = X.copy()
                        st.session_state.cat_cols_viz = cat_cols.copy()
                        st.session_state.num_cols_viz = num_cols.copy()

                        # Продолжаем предобработку
                        # 2. Кодирование категориальных признаков
                        if len(cat_cols) > 0:
                            # Ordinal Encoding для бинарных категориальных признаков
                            binary_cat_cols = []
                            for col in cat_cols:
                                if X_train[col].nunique() == 2:
                                    binary_cat_cols.append(col)

                            if binary_cat_cols:
                                oe = OrdinalEncoder()
                                for col in binary_cat_cols:
                                    try:
                                        X_train[col] = oe.fit_transform(X_train[[col]])
                                        X_test[col] = oe.transform(X_test[[col]])
                                    except:
                                        le_col = LabelEncoder()
                                        X_train[col] = le_col.fit_transform(X_train[col])
                                        X_test[col] = le_col.transform(X_test[col])

                            # One-Hot Encoding для остальных категориальных
                            non_binary_cat = [col for col in cat_cols if col not in binary_cat_cols]
                            if non_binary_cat:
                                X_train = pd.get_dummies(X_train, columns=non_binary_cat, drop_first=True)
                                X_test = pd.get_dummies(X_test, columns=non_binary_cat, drop_first=True)
                                train_cols = X_train.columns
                                test_cols = X_test.columns
                                missing_cols = set(train_cols) - set(test_cols)
                                for col in missing_cols:
                                    X_test[col] = 0
                                X_test = X_test[train_cols]

                        # 3. SMOTE балансировка
                        smote = SMOTE(random_state=42)
                        X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

                        unique_before, counts_before = np.unique(y_train, return_counts=True)
                        unique_after, counts_after = np.unique(y_train_resampled, return_counts=True)

                        st.success("SMOTE применен успешно!")
                        st.write(f"До SMOTE: {dict(zip(unique_before, counts_before))}")
                        st.write(f"После SMOTE: {dict(zip(unique_after, counts_after))}")

                        X_train = X_train_resampled
                        y_train = y_train_resampled


                        # 4. Удаление выбросов - IQR метод
                        if len(num_cols) > 0:
                            train_clean = X_train.copy()
                            test_clean = X_test.copy()

                            for col in num_cols:
                                if col in train_clean.columns:
                                    Q1 = train_clean[col].quantile(0.1)
                                    Q3 = train_clean[col].quantile(0.9)
                                    IQR = Q3 - Q1
                                    lower = Q1 - 1.5 * IQR
                                    upper = Q3 + 1.5 * IQR

                                    train_clean[col] = np.clip(train_clean[col], lower, upper)
                                    if col in test_clean.columns:
                                        test_clean[col] = np.clip(test_clean[col], lower, upper)

                            X_train = train_clean
                            X_test = test_clean

                        # 5. Масштабирование
                        if len(num_cols) > 0:
                            scaler = StandardScaler()
                            current_num_cols = [col for col in num_cols if col in X_train.columns]
                            if current_num_cols:
                                X_train[current_num_cols] = scaler.fit_transform(X_train[current_num_cols])
                                X_test[current_num_cols] = scaler.transform(X_test[current_num_cols])
                                st.session_state.scaler = scaler

                        # 6. PCA если много признаков
                        if X_train.shape[1] > 10:
                            pca = PCA(n_components=0.9)
                            X_train = pca.fit_transform(X_train)
                            X_test = pca.transform(X_test)
                            explained_variance = np.sum(pca.explained_variance_ratio_)
                            st.success(
                                f"PCA применен: {X_train.shape[1]} компонент, объясненная дисперсия: {explained_variance:.2%}")
                            st.session_state.pca = pca

                        # Сохраняем в session_state
                        st.session_state.X_train = X_train
                        st.session_state.X_test = X_test
                        st.session_state.y_train = y_train
                        st.session_state.y_test = y_test
                        st.session_state.feature_names = X_train.columns.tolist() if hasattr(X_train, 'columns') else [
                            f'feature_{i}' for i in range(X_train.shape[1])]

                        st.session_state.data_preprocessed = True
                        st.session_state.prepare_data = False

                        st.success(f"Данные подготовлены. Train: {X_train.shape}, Test: {X_test.shape}")

                        # Показываем информацию о классах
                        unique_classes, class_counts = np.unique(y_train, return_counts=True)
                        st.subheader("Распределение классов в обучающих данных")

                        for cls, count in zip(unique_classes, class_counts):
                            percentage = count / len(y_train) * 100
                            st.write(f"Класс {cls}: {count} примеров ({percentage:.1f}%)")

                if st.session_state.data_preprocessed:
                    st.header("Визуализация данных")

                    # Получаем данные для визуализации из session_state
                    X_for_viz = st.session_state.X_for_viz
                    cat_cols = st.session_state.cat_cols_viz
                    num_cols = st.session_state.num_cols_viz

                    # Создаем отдельные контейнеры для визуализаций
                    viz_container = st.container()

                    with viz_container:
                        # Круговые диаграммы для категориальных признаков
                        if len(cat_cols) > 0:
                            st.subheader("Круговые диаграммы для категориальных признаков")
                            selected_cat = st.selectbox("Выберите признак",
                                                        cat_cols[:min(5, len(cat_cols))],
                                                        key='cat_select')

                            if selected_cat in X_for_viz.columns:
                                value_counts = X_for_viz[selected_cat].value_counts().head(10)
                                fig, ax = plt.subplots(figsize=(8, 6))
                                ax.pie(value_counts.values, labels=value_counts.index, autopct='%1.1f%%')
                                ax.set_title(f"Распределение: {selected_cat}")
                                st.pyplot(fig)

                        # Распределение для числовых признаков
                        if len(num_cols) > 0:
                            st.subheader("Распределение числовых признаков")
                            selected_num = st.selectbox("Выберите признак",
                                                        num_cols[:min(5, len(num_cols))],
                                                        key='num_select')
                            if selected_num in X_for_viz.columns:
                                fig, ax = plt.subplots(figsize=(8, 5))
                                ax.hist(X_for_viz[selected_num].dropna(), bins=30, edgecolor='black', alpha=0.7)
                                ax.set_title(f"Распределение: {selected_num}")
                                ax.set_xlabel(selected_num)
                                ax.set_ylabel("Частота")
                                ax.grid(True, alpha=0.3)
                                st.pyplot(fig)

                        # Ящик с усами для числовых признаков
                        if len(num_cols) > 0:
                            st.subheader("Boxplot для числовых признаков")
                            selected_box = st.multiselect(
                                "Выберите признаки",
                                num_cols[:min(5, len(num_cols))],
                                default=num_cols[:min(3, len(num_cols))],
                                key='box_select'
                            )
                            if selected_box:
                                fig, ax = plt.subplots(figsize=(10, 6))
                                data_to_plot = [X_for_viz[col].dropna() for col in selected_box]
                                ax.boxplot(data_to_plot, labels=selected_box)
                                ax.set_title("Boxplot выбранных признаков")
                                ax.set_ylabel("Значения")
                                ax.grid(True, alpha=0.3)
                                plt.xticks(rotation=45)
                                st.pyplot(fig)

                        # Парные графики (scatter plot)
                        if len(num_cols) >= 2:
                            st.subheader("Парные отношения признаков")
                            col1 = st.selectbox("Первый признак", num_cols, key='pair1')
                            col2 = st.selectbox("Второй признак", [c for c in num_cols if c != col1], key='pair2')

                            fig, ax = plt.subplots(figsize=(8, 6))
                            scatter = ax.scatter(X_for_viz[col1], X_for_viz[col2], alpha=0.5, s=20)
                            ax.set_xlabel(col1)
                            ax.set_ylabel(col2)
                            ax.set_title(f'Парные отношения: {col1} vs {col2}')
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)

                        # Корреляционная матрица
                        if len(num_cols) > 1:
                            st.subheader("Корреляционная матрица")
                            fig, ax = plt.subplots(figsize=(10, 8))
                            corr_matrix = X_for_viz[num_cols].corr()
                            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm',
                                        center=0, ax=ax, square=True, cbar_kws={"shrink": 0.8})
                            ax.set_title('Корреляционная матрица числовых признаков')
                            st.pyplot(fig)
            else:
                st.error(f"Целевая переменная '{target_col}' не найдена")

        # Вкладка 2: Моделирование
        with tab2:
            st.header("Моделирование")

            if 'X_train' in st.session_state:
                X_train = st.session_state.X_train
                X_test = st.session_state.X_test
                y_train = st.session_state.y_train
                y_test = st.session_state.y_test
                feature_names = st.session_state.feature_names

                # Выбор модели
                model_choice = st.selectbox(
                    "Выберите модель",
                    ["XGBoost", "Random Forest", "Logistic Regression"]
                )

                # Настройки Optuna
                n_trials = st.slider("Количество испытаний Optuna", 5, 30, 10)

                if st.button("Обучить модель", type="primary", use_container_width=True):
                    with st.spinner("Обучение модели с помощью Optuna"):
                        # Функция для Optuna
                        def objective(trial):
                            if model_choice == "XGBoost":
                                params = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                                    'max_depth': trial.suggest_int('max_depth', 3, 10),
                                    'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                                    'subsample': trial.suggest_float('subsample', 0.6, 1.0),
                                    'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
                                    'random_state': 42
                                }
                                model = XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')

                            elif model_choice == "Random Forest":
                                params = {
                                    'n_estimators': trial.suggest_int('n_estimators', 50, 300),
                                    'max_depth': trial.suggest_int('max_depth', 3, 20),
                                    'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),
                                    'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),
                                    'random_state': 42
                                }
                                model = RandomForestClassifier(**params)

                            else:  # Logistic Regression
                                params = {
                                    'C': trial.suggest_float('C', 0.01, 10.0, log=True),
                                    'max_iter': trial.suggest_int('max_iter', 100, 1000),
                                    'random_state': 42
                                }
                                model = LogisticRegression(**params)

                            score = cross_val_score(model, X_train, y_train, cv=3, scoring='roc_auc').mean()
                            return score

                        # Запуск Optuna
                        study = optuna.create_study(direction='maximize')
                        study.optimize(objective, n_trials=n_trials, show_progress_bar=False)

                        # Лучшие параметры
                        best_params = study.best_params
                        st.success(f"Лучшие параметры: {best_params}")

                        # Создание и обучение модели с лучшими параметрами
                        if model_choice == "XGBoost":
                            model = XGBClassifier(**best_params, use_label_encoder=False,
                                                  eval_metric='logloss', random_state=42)
                        elif model_choice == "Random Forest":
                            model = RandomForestClassifier(**best_params, random_state=42)
                        else:
                            model = LogisticRegression(**best_params, random_state=42)

                        model.fit(X_train, y_train)

                        # Предсказания
                        y_pred = model.predict(X_test)
                        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else None

                        # Метрики
                        st.subheader("Метрики модели")

                        col1, col2, col3, col4 = st.columns(4)
                        with col1:
                            accuracy = accuracy_score(y_test, y_pred)
                            st.metric("Accuracy", f"{accuracy:.3f}")
                        with col2:
                            precision = precision_score(y_test, y_pred, average='weighted')
                            st.metric("Precision", f"{precision:.3f}")
                        with col3:
                            recall = recall_score(y_test, y_pred, average='weighted')
                            st.metric("Recall", f"{recall:.3f}")
                        with col4:
                            f1 = f1_score(y_test, y_pred, average='weighted')
                            st.metric("F1-Score", f"{f1:.3f}")

                        # ROC-AUC
                        if y_pred_proba is not None:
                            try:
                                roc_auc = roc_auc_score(y_test, y_pred_proba)
                                st.metric("ROC-AUC", f"{roc_auc:.3f}")
                            except:
                                pass

                        # Примеры предсказаний
                        st.subheader("Примеры предсказаний")
                        n_samples = min(5, len(X_test))
                        sample_indices = np.random.choice(len(X_test), n_samples, replace=False)

                        predictions_df = pd.DataFrame({
                            'Фактический': y_test[sample_indices],
                            'Предсказанный': y_pred[sample_indices]
                        })

                        st.dataframe(predictions_df)

                        # График ошибок
                        st.subheader("Матрица ошибок")
                        fig, ax = plt.subplots(figsize=(6, 5))
                        cm = confusion_matrix(y_test, y_pred)
                        disp = ConfusionMatrixDisplay(confusion_matrix=cm)
                        disp.plot(ax=ax, cmap='Blues')
                        ax.set_title("Матрица ошибок")
                        st.pyplot(fig)

                        # ROC-кривая
                        if y_pred_proba is not None:
                            st.subheader("ROC-кривая")
                            fig, ax = plt.subplots(figsize=(6, 5))
                            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
                            roc_auc = auc(fpr, tpr)

                            ax.plot(fpr, tpr, color='darkorange', lw=2,
                                    label=f'ROC curve (AUC = {roc_auc:.3f})')
                            ax.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
                            ax.set_xlim([0.0, 1.0])
                            ax.set_ylim([0.0, 1.05])
                            ax.set_xlabel('False Positive Rate')
                            ax.set_ylabel('True Positive Rate')
                            ax.set_title('ROC Curve')
                            ax.legend(loc="lower right")
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)

                        # Отчет по классификации
                        st.subheader("Отчет по классификации")
                        report = classification_report(y_test, y_pred, output_dict=True)
                        report_df = pd.DataFrame(report).transpose()
                        st.dataframe(report_df.style.format("{:.3f}"))

            else:
                st.info("Сначала подготовьте данные на вкладке 'Предобработка'")
    else:
        st.info("Загрузите CSV файл или используйте демо-данные для начала работы")


if __name__ == "__main__":
    main()
