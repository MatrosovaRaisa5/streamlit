import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, OrdinalEncoder
from sklearn.decomposition import PCA
from sklearn.impute import SimpleImputer
import warnings
import xgboost

warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫–∞",
    layout="wide"
)

st.title("–†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –ø—Ä–æ—Ñ–∏–ª—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
st.markdown("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–∏–ø–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö —Å –¥–∞—Ç—á–∏–∫–æ–≤")

tab1, tab2 = st.tabs(["üìä –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏", "üîÆ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"])

with tab1:
    st.header("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏")

    st.subheader("–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –º–æ–¥–µ–ª—å")
    st.markdown("""
    –ú–æ–¥–µ–ª—å: XGBoost (Gradient Boosting)

    –¢–∏–ø –∑–∞–¥–∞—á–∏: –ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è

    –ö–ª–∞—Å—Å—ã –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:
    - 1: driving
    - 2: non-study activity
    - 3: walking
    - 4: descending stairs

    –û–ø–∏—Å–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏:
    –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∞–∫—Å–µ–ª–µ—Ä–æ–º–µ—Ç—Ä–∏–∏, —Å–æ–±—Ä–∞–Ω–Ω—ã—Ö –≤–æ –≤—Ä–µ–º—è —Ö–æ–¥—å–±—ã –Ω–∞ —Å–≤–µ–∂–µ–º –≤–æ–∑–¥—É—Ö–µ, –ø–æ–¥—ä–µ–º–∞ 
    –ø–æ –ª–µ—Å—Ç–Ω–∏—Ü–µ –∏ –≤–æ–∂–¥–µ–Ω–∏—è –∞–≤—Ç–æ–º–æ–±–∏–ª—è –¥–ª—è 200 –∑–¥–æ—Ä–æ–≤—ã—Ö –≤–∑—Ä–æ—Å–ª—ã—Ö –ª—é–¥–µ–π.
    """)

    st.subheader("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric("–í—Å–µ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤", "20")
        st.metric("–ü–æ—Å–ª–µ PCA", "15")

    with col2:
        st.metric("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤", "4")
        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", "90%+")

    with col3:
        st.metric("–ú–æ–¥–µ–ª—å", "XGBoost")
        st.metric("–ü—Ä–∏–∑–Ω–∞–∫–∏", "—á–∏—Å–ª–æ–≤—ã–µ")

    st.subheader("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
    st.markdown("""
    –§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã:

    –û—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
    - time_s: –í—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
    - lh_x, lh_y, lh_z: –î–∞–Ω–Ω—ã–µ —Å –ª–µ–≤–æ–π —Ä—É–∫–∏
    - rh_x, rh_y, rh_z: –î–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–æ–π —Ä—É–∫–∏
    - la_x, la_y, la_z: –î–∞–Ω–Ω—ã–µ —Å –ª–µ–≤–æ–π –Ω–æ–≥–∏
    - ra_x, ra_y, ra_z: –î–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–æ–π –Ω–æ–≥–∏
    - back_x, back_y, back_z: –î–∞–Ω–Ω—ã–µ —Å–æ —Å–ø–∏–Ω—ã

    –î–µ–º–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ:
    - gender: –ü–æ–ª (male/female)
    - age: –í–æ–∑—Ä–∞—Å—Ç
    - race: –†–∞—Å–∞ (caucasian/asian/black)
    - right_handed: –ü—Ä–∞–≤—à–∞ (0/1)
    """)

    st.subheader("–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")

    example_data = {
        'time_s': [1.0],
        'lh_x': [0.12], 'lh_y': [-0.45], 'lh_z': [9.81],
        'rh_x': [0.15], 'rh_y': [-0.42], 'rh_z': [9.79],
        'la_x': [0.08], 'la_y': [-0.48], 'la_z': [9.80],
        'ra_x': [0.10], 'ra_y': [-0.46], 'ra_z': [9.82],
        'back_x': [0.05], 'back_y': [-0.50], 'back_z': [9.78],
        'gender': ['male'],
        'age': [25],
        'race': ['caucasian'],
        'right_handed': [1]
    }

    example_df = pd.DataFrame(example_data)
    st.dataframe(example_df, use_container_width=True)

    st.subheader("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")

    steps = [
        "1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö",
        "2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤",
        "3. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤",
        "4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±—Ä–æ—Å–æ–≤ –º–µ—Ç–æ–¥–æ–º IQR",
        "5. –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö",
        "6. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤",
        "7. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏",
        "8. –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é XGBoost"
    ]

    for step in steps:
        st.markdown(f"‚úÖ {step}")

with tab2:
    st.header("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")

    @st.cache_resource
    def load_model_and_preprocessing():
        try:
            with open('xgb_clf.pkl', 'rb') as f:
                model = pickle.load(f)
            
            # –¢–∞–∫–∂–µ –∑–∞–≥—Ä—É–∑–∏–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
            # –ï—Å–ª–∏ –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω–æ, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏—Ö –∑–¥–µ—Å—å
            # –ù–∞–ø—Ä–∏–º–µ—Ä: imputer, scaler, pca, encoders
            # –ï—Å–ª–∏ –Ω–µ—Ç, —Å–æ–∑–¥–∞–¥–∏–º –Ω–æ–≤—ã–µ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏
            return model
        except FileNotFoundError:
            st.error("–§–∞–π–ª –º–æ–¥–µ–ª–∏ 'xgb_clf.pkl' –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return None

    model = load_model_and_preprocessing()

    if model is not None:
        st.success("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")

        def preprocess_single_row(df_row):
            df = df_row.copy()
            
            # 1. –£–¥–∞–ª–µ–Ω–∏–µ subj_id, –µ—Å–ª–∏ –µ—Å—Ç—å
            if 'subj_id' in df.columns:
                df = df.drop('subj_id', axis=1)
            
            # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
            num_cols = [col for col in df.columns if (df[col].dtype == 'int64' or df[col].dtype == 'float64')]
            cat_cols = [col for col in df.columns if df[col].dtype == 'object']
            
            # 3. –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            imputer = SimpleImputer(strategy='mean')
            if num_cols:
                df[num_cols] = imputer.fit_transform(df[num_cols])
            
            # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            for col in cat_cols:
                if col == 'gender':
                    # –°–æ–∑–¥–∞–µ–º encoder –¥–ª—è gender
                    gender_encoder = OrdinalEncoder(categories=[['female', 'male']])
                    try:
                        df[col] = gender_encoder.fit_transform(df[[col]])
                    except:
                        # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å –Ω–µ–∑–Ω–∞–∫–æ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        df[col] = 0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é female
                elif col == 'race':
                    # –°–æ–∑–¥–∞–µ–º encoder –¥–ª—è race
                    race_categories = [['caucasian', 'asian', 'black']]
                    race_encoder = OrdinalEncoder(categories=race_categories)
                    try:
                        df[col] = race_encoder.fit_transform(df[[col]])
                    except:
                        # –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å –Ω–µ–∑–Ω–∞–∫–æ–º–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        df[col] = 0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é caucasian
                elif col == 'right_handed':
                    # right_handed —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —á–∏—Å–ª–æ–≤—ã–º, –Ω–æ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
                    if df[col].dtype == 'object':
                        df[col] = df[col].map({'yes': 1, 'no': 0, '1': 1, '0': 0})
            
            # 5. –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
            scaler = StandardScaler()
            if num_cols:
                df[num_cols] = scaler.fit_transform(df[num_cols])
            
            # 6. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ PCA –¥–ª—è —É–º–µ–Ω—å—à–µ–Ω–∏—è –¥–æ 15 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç
            pca = PCA(n_components=15)
            pca_data = pca.fit_transform(df)
            
            return pca_data

        # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

        uploaded_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
            type=['csv'],
            help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É —Å –¥–∞–Ω–Ω—ã–º–∏"
        )

        if uploaded_file is not None:
            try:
                try:
                    data = pd.read_csv(uploaded_file, sep='$')
                except:
                    data = pd.read_csv(uploaded_file)

                st.success(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {data.shape[0]} —Å—Ç—Ä–æ–∫, {data.shape[1]} —Å—Ç–æ–ª–±—Ü–æ–≤")

                # –ü–æ–∫–∞–∑–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                with st.expander("–ü—Ä–æ—Å–º–æ—Ç—Ä –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö", expanded=True):
                    st.dataframe(data, use_container_width=True)

                if len(data) > 1:
                    st.warning("–§–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –±–æ–ª–µ–µ –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏. –ë—É–¥—É—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã –≤—Å–µ —Å—Ç—Ä–æ–∫–∏.")

                if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ", type="primary", use_container_width=True):
                    with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è..."):
                        try:
                            processed_data = preprocess_single_row(data)
                            
                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                            st.info(f"–ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏: {processed_data.shape[1]} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
                            
                            predictions = model.predict(processed_data)
                            probabilities = model.predict_proba(processed_data)

                            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

                            for i in range(len(predictions)):
                                st.markdown(f"**–°—Ç—Ä–æ–∫–∞ {i + 1}:**")

                                col1, col2 = st.columns(2)

                                with col1:
                                    activity_map = {
                                        0: "descending stairs",
                                        1: "driving",
                                        2: "non-study activity",
                                        3: "walking"
                                    }
                                    pred_class = int(predictions[i])
                                    pred_name = activity_map.get(pred_class, f"–ö–ª–∞—Å—Å {pred_class}")

                                    st.metric("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å", pred_name)

                                with col2:
                                    max_prob = np.max(probabilities[i]) * 100
                                    st.metric("–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏", f"{max_prob:.1f}%")

                                st.markdown("**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º:**")

                                prob_df = pd.DataFrame({
                                    '–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å': [activity_map.get(j, f"–ö–ª–∞—Å—Å {j}") for j in range(len(probabilities[i]))],
                                    '–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å': [f"{p * 100:.2f}%" for p in probabilities[i]]
                                })

                                prob_df = prob_df.sort_values('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å', ascending=False)

                                st.dataframe(prob_df, use_container_width=True, hide_index=True)

                                fig, ax = plt.subplots(figsize=(10, 4))
                                y_pos = np.arange(len(probabilities[i]))
                                ax.barh(y_pos, probabilities[i], color='steelblue')
                                ax.set_yticks(y_pos)
                                ax.set_yticklabels([activity_map.get(j, f"–ö–ª–∞—Å—Å {j}") for j in range(len(probabilities[i]))])
                                ax.set_xlabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
                                ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º')
                                ax.invert_yaxis()
                                ax.set_xlim([0, 1])
                                st.pyplot(fig)

                            st.success("‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")
                            
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö: {str(e)}")
                            st.info("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∏–º–µ—é—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Å—Ç–æ–ª–±—Ü—ã.")

            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")
                st.info("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞. –û–∂–∏–¥–∞–µ—Ç—Å—è CSV —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º '$' –∏–ª–∏ –∑–∞–ø—è—Ç—ã–º–∏.")
        else:
            st.info("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∏–º–µ—Ä –Ω–∏–∂–µ:")

            example_data = pd.DataFrame({
                'time_s': [1.0],
                'lh_x': [0.12], 'lh_y': [-0.45], 'lh_z': [9.81],
                'rh_x': [0.15], 'rh_y': [-0.42], 'rh_z': [9.79],
                'la_x': [0.08], 'la_y': [-0.48], 'la_z': [9.80],
                'ra_x': [0.10], 'ra_y': [-0.46], 'ra_z': [9.82],
                'back_x': [0.05], 'back_y': [-0.50], 'back_z': [9.78],
                'gender': ['male'],
                'age': [25],
                'race': ['caucasian'],
                'right_handed': [1]
            })

            csv = example_data.to_csv(index=False, sep='$')

            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
                data=csv,
                file_name="example_prediction_data.csv",
                mime="text/csv",
                help="–°–∫–∞—á–∞–π—Ç–µ —ç—Ç–æ—Ç —Ñ–∞–π–ª, –∑–∞–ø–æ–ª–Ω–∏—Ç–µ —Å–≤–æ–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"
            )

            with st.expander("–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–∏–º–µ—Ä–∞ —Ñ–∞–π–ª–∞"):
                st.dataframe(example_data, use_container_width=True)
                st.markdown("""
                **–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:**
                1. –°–∫–∞—á–∞–π—Ç–µ –ø—Ä–∏–º–µ—Ä —Ñ–∞–π–ª–∞
                2. –û—Ç–∫—Ä–æ–π—Ç–µ –≤ Excel –∏–ª–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ä–µ–¥–∞–∫—Ç–æ—Ä–µ
                3. –ó–∞–º–µ–Ω–∏—Ç–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–≤–æ–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (—Ç–æ–ª—å–∫–æ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞)
                4. –°–æ—Ö—Ä–∞–Ω–∏—Ç–µ –∫–∞–∫ CSV —Ñ–∞–π–ª
                5. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±—Ä–∞—Ç–Ω–æ –≤ —Ñ–æ—Ä–º—É –≤—ã—à–µ
                """)
    else:
        st.error("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª 'xgb_clf.pkl' –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ.")

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>–î–∞—à–±–æ—Ä–¥ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ —á–µ–ª–æ–≤–µ–∫–∞ | by –ú–∞—Ç—Ä–æ—Å–æ–≤–∞ –†–∞–∏—Å–∞</p>
</div>
""", unsafe_allow_html=True)
